{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3150588-da27-4fe4-a487-165448b8a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import dlib\n",
    "import imutils\n",
    "import os\n",
    "import joblib\n",
    "import cvlib as cv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "77e90e9d-4030-4e5b-ac21-5264f6434e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cvlib\n",
      "  Downloading cvlib-0.2.7.tar.gz (13.1 MB)\n",
      "     ---------------------------------------- 0.0/13.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/13.1 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/13.1 MB 4.3 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 1.1/13.1 MB 9.8 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 2.1/13.1 MB 14.8 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 3.2/13.1 MB 17.0 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 4.5/13.1 MB 19.0 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 7.1/13.1 MB 25.2 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.8/13.1 MB 28.6 MB/s eta 0:00:01\n",
      "     --------------------------------------  13.1/13.1 MB 54.4 MB/s eta 0:00:01\n",
      "     --------------------------------------- 13.1/13.1 MB 43.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\veere\\anaconda3\\lib\\site-packages (from cvlib) (1.26.4)\n",
      "Collecting progressbar (from cvlib)\n",
      "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests in c:\\users\\veere\\anaconda3\\lib\\site-packages (from cvlib) (2.32.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\veere\\anaconda3\\lib\\site-packages (from cvlib) (10.3.0)\n",
      "Requirement already satisfied: imageio in c:\\users\\veere\\anaconda3\\lib\\site-packages (from cvlib) (2.33.1)\n",
      "Requirement already satisfied: imutils in c:\\users\\veere\\anaconda3\\lib\\site-packages (from cvlib) (0.5.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\veere\\anaconda3\\lib\\site-packages (from requests->cvlib) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\veere\\anaconda3\\lib\\site-packages (from requests->cvlib) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\veere\\anaconda3\\lib\\site-packages (from requests->cvlib) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\veere\\anaconda3\\lib\\site-packages (from requests->cvlib) (2024.7.4)\n",
      "Building wheels for collected packages: cvlib, progressbar\n",
      "  Building wheel for cvlib (setup.py): started\n",
      "  Building wheel for cvlib (setup.py): finished with status 'done'\n",
      "  Created wheel for cvlib: filename=cvlib-0.2.7-py3-none-any.whl size=10046381 sha256=5c770f4f07bf24dd17827621334e3f3a9b738403e25b5012849d7c696ea38b43\n",
      "  Stored in directory: c:\\users\\veere\\appdata\\local\\pip\\cache\\wheels\\83\\07\\aa\\65f82dedaf511cdd3ff55778ddb8867161334ac786e52651e0\n",
      "  Building wheel for progressbar (setup.py): started\n",
      "  Building wheel for progressbar (setup.py): finished with status 'done'\n",
      "  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12084 sha256=943ecbf585501f108d15b0d2ab62fd55501c1357daa175bf430679f7ccb0dcc0\n",
      "  Stored in directory: c:\\users\\veere\\appdata\\local\\pip\\cache\\wheels\\a5\\4d\\c7\\f3cf0f75c746c219090060131fe00f1523cc2c5484991f4030\n",
      "Successfully built cvlib progressbar\n",
      "Installing collected packages: progressbar, cvlib\n",
      "Successfully installed cvlib-0.2.7 progressbar-2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install cvlib\n",
    "!pip install opencv-python\n",
    "!pip install imutils\n",
    "!pip install tensorflow\n",
    "!pip install joblib\n",
    "!pip install dlib-19.24.99-cp312-cp312-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f26c47a-5a28-41aa-b06c-79b67e598689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for gender recognition \n",
    "\n",
    "def gender_recognition(image_path):\n",
    "    #preprocessing\n",
    "    img_size = (128, 128)  # Target size for images\n",
    "    front_img = load_img(image_path, target_size=img_size)\n",
    "    front_img = img_to_array(front_img)\n",
    "    front_img = np.expand_dims(front_img, axis=0) \n",
    "\n",
    "    #loading our pretrained model\n",
    "    model = load_model(\"./pretrained_models/front_model.h5\")\n",
    "    # Make a prediction\n",
    "    prediction = model.predict(front_img)\n",
    "    \n",
    "    # Interpret the prediction\n",
    "    if prediction[0][0] > 0.5:\n",
    "        return \"Female\"\n",
    "    else:\n",
    "        return \"Male\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cc00748-8972-4679-a598-248c97152a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting facial features from the image using a pretrained model\n",
    "# Load the pre-trained facial landmarks model\n",
    "landmark_model_path = \"./pretrained_models/shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(landmark_model_path)\n",
    "\n",
    "def extract_landmarks(image_path):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = imutils.resize(image, width=600)\n",
    "\n",
    "    if image is None:\n",
    "        print(\"Hello\")\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the image\n",
    "    faces = detector(gray)\n",
    "    if len(faces) == 0:\n",
    "        print(\"No faces detected!\")\n",
    "        return None\n",
    "\n",
    "    # Assume the first face detected is the target face\n",
    "    landmarks = predictor(gray, faces[0])\n",
    "\n",
    "    # Extract (x, y) coordinates of the landmarks\n",
    "    points = []\n",
    "    for n in range(68):\n",
    "        x = landmarks.part(n).x\n",
    "        y = landmarks.part(n).y\n",
    "        points.append((x, y))\n",
    "\n",
    "    return points\n",
    "\n",
    "def compute_features(front_landmarks, side_landmarks=None):\n",
    "    # Cheek-to-Jaw Width Ratio (CJWR)\n",
    "    jaw_width = np.linalg.norm(np.array(front_landmarks[3]) - np.array(front_landmarks[13]))\n",
    "    cheek_width = np.linalg.norm(np.array(front_landmarks[1]) - np.array(front_landmarks[15]))\n",
    "    cjwr = cheek_width / jaw_width\n",
    "\n",
    "    # Width to Upper Facial Height Ratio (WHR)\n",
    "    width = np.linalg.norm(np.array(front_landmarks[1]) - np.array(front_landmarks[15]))\n",
    "    upper_height = np.linalg.norm(np.array(front_landmarks[27]) - np.array(front_landmarks[8]))\n",
    "    whr = width / upper_height\n",
    "\n",
    "    # Perimeter to Area Ratio (PAR)\n",
    "    contour_points = np.array(front_landmarks[:17])  # Jawline points\n",
    "    perimeter = cv2.arcLength(contour_points, True)\n",
    "    area = cv2.contourArea(contour_points)\n",
    "    par = perimeter / area if area != 0 else None\n",
    "\n",
    "    # Eye Size (ES)\n",
    "    left_eye_width = np.linalg.norm(np.array(front_landmarks[36]) - np.array(front_landmarks[39]))\n",
    "    left_eye_height = np.linalg.norm(np.array(front_landmarks[37]) - np.array(front_landmarks[41]))\n",
    "    right_eye_width = np.linalg.norm(np.array(front_landmarks[42]) - np.array(front_landmarks[45]))\n",
    "    right_eye_height = np.linalg.norm(np.array(front_landmarks[43]) - np.array(front_landmarks[47]))\n",
    "    es = ((left_eye_width * left_eye_height) + (right_eye_width * right_eye_height)) / 2\n",
    "\n",
    "    # Lower Face to Face Height Ratio (FW/FH)\n",
    "    lower_face_height = np.linalg.norm(np.array(front_landmarks[33]) - np.array(front_landmarks[8]))\n",
    "    face_height = np.linalg.norm(np.array(front_landmarks[27]) - np.array(front_landmarks[8]))\n",
    "    fw_fh = lower_face_height / face_height\n",
    "\n",
    "    # Mean Eyebrow Height (MEH)\n",
    "    left_eyebrow_mean_height = np.mean([np.linalg.norm(np.array(front_landmarks[19]) - np.array(front_landmarks[37])),\n",
    "                                        np.linalg.norm(np.array(front_landmarks[20]) - np.array(front_landmarks[38]))])\n",
    "    right_eyebrow_mean_height = np.mean([np.linalg.norm(np.array(front_landmarks[23]) - np.array(front_landmarks[43])),\n",
    "                                         np.linalg.norm(np.array(front_landmarks[24]) - np.array(front_landmarks[44]))])\n",
    "    meh = (left_eyebrow_mean_height + right_eyebrow_mean_height) / 2\n",
    "\n",
    "    return {\n",
    "        \"front_CJWR\": cjwr,\n",
    "        \"front_WHR\": whr,\n",
    "        \"front_PAR\": par,\n",
    "        \"front_ES\": es,\n",
    "        \"front_FW/FH\": fw_fh,\n",
    "        \"front_MEH\": meh\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b59ce1e-d124-4962-ab17-0fd3e62a38be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bmi classification\n",
    "def bmi_class(bmi):\n",
    "    if bmi<18.5:\n",
    "        return \"underweight\"\n",
    "    elif bmi<24.9:\n",
    "        return \"normal\"\n",
    "    elif bmi<29.9:\n",
    "        return \"overweight\"\n",
    "    elif bmi>=29.9:\n",
    "        return \"obesity\"\n",
    "    else:\n",
    "        return \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9d6be5d-6044-42a6-8e77-999ead1e821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('models/linear_reg.pkl')\n",
    "model2 = joblib.load('models/cat_reg.pkl')\n",
    "model3 = joblib.load('models/linear_reg2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efda3a26-d708-4522-909e-614dd1baa7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step\n",
      "Male\n",
      "[[25.02032039]]\n",
      "overweight\n",
      "[25.02868681]\n",
      "overweight\n",
      "[[24.2140293]]\n",
      "normal\n"
     ]
    }
   ],
   "source": [
    "path = './test_images/ritesh.jpg'\n",
    "\n",
    "landmarks = extract_landmarks(path)\n",
    "features = compute_features(landmarks)\n",
    "\n",
    "df = pd.DataFrame([features])\n",
    "sex = gender_recognition(path)\n",
    "df['sex'] = 0 if sex==\"Male\" else 1 \n",
    "# print(df['sex'])\n",
    "print(sex)\n",
    "y = model.predict(df)\n",
    "y2 = model2.predict(df)\n",
    "y3 = model3.predict(df)\n",
    "print(y)\n",
    "print(bmi_class(y))\n",
    "print(y2)\n",
    "print(bmi_class(y2))\n",
    "print(y3)\n",
    "print(bmi_class(y3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3374acc7-9311-4cf5-adc2-6de50e7cb2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
